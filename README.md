# KaggleBronze_AIJC_detector
This is my first kaggle medal, after trying many competitions and only getting a bronze medal, but I still wanted to show it.

The data set for this competition only has three AI texts, but a lot of human texts. Therefore, this is a very unbalanced data set, so the organizers of the competition actually hope that we can deploy some large language models ourselves. Therefore, I used some well-known large language models to generate some pseudo data to supplement the data. 

I believe that everyone is familiar with the binary classification task, but the difficulties of this competition are as follows. First, the organizer artificially modified the text generated by AI and added some spelling errors. As a result, our local cross-validation results are very high, and CV verification can even reach a high score of 0.99, but the public list is only 0.8 or even lower. Second, the official has limited the article types of AI-generated texts, which we can use as some prompts. In the data set, only 2 types of prompts are included, but when verifying the public list, five other unknown prompts are included for accuracy score verification. Therefore, it is crucial to make good use of daily upload opportunities and find the other five prompts. Third: The overfitting problem of the transformer model. This problem is very similar to the first problem: because the organizer artificially introduced some spelling errors, some deep learning models (such as BERT, deBERT, etc.) cannot be used and trained(Maybe someone can make them useful, but I cannot figure it out at that time).

Only one pipeline was used for this competition, and only one notebook was allowed to contain both training and inference processes. And I used a special library in this competition, called leven_search, which is a library specially designed for this competition to detect spelling errors. Using this specialized library, I created a function called “sentence_correcter” that finds spelling errors and corrects them, removing this artificially created interference and noise. This is how I solved the first challenge.

The training data set I used was collected by myself, most of which came from sharing in the discussion area, and I controlled the amount of data collected to make it close to the maximum value that Kaggle could collect and use. This dataset has been deduplicated and normalized. Normalization specifically means that since I learned from the discussion forum that text data related to three prompts will lead to a significant drop in the final score, I removed all the text related to these three prompts. 

I used traditional machine learning methods because the number of parameters that need to be adjusted is relatively small compared to neural networks. But this created another problem: traditional machine learning methods generally work on numerical data, but this competition used text data. So I first mapped the text data into a matrix, which is the word segmentation process we often use. In this link, I did not use the word segmentation built by others, which is also to avoid the problems caused by misspelled data. Because there are different types of errors in spelling errors caused by humans and spelling errors generated by AI, etc. If they are uniformly converted into unknown words or a type of error, it will undoubtedly cause confusion. Therefore, I built a unique tokenizer. I built this tokenizer using the BPE(Byte-Pair Encoding) on the test dataset. Some normalization methods I used: NFC and adding case sensitivity, adding special tokens, and expected vocabulary length. 

Use of TF-IDF: The text token after word segmentation is individually assigned a TF-IDF value, which can then be represented in the form of a vector. min_df is set to 0: we consider words that appear only once in a text(those errors), as they are very important factors in this competition. 

I built models for Naive Bayes, SGD classifier, and LGBM classifier, and submitted the result after adjusting parameters and using ensemble for weighted voting.

And finally, I ranked in the top 9% of the 2,175 teams and won the bronze medal.
